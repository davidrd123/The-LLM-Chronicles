# Notation Recommendations for "The LLM Chronicles"

## Input Text (Complete Sentences/Prompts)
Use *italicized text in quotation marks* for any complete text being processed by the model:
- *"The cat chased the dog because it was fast."*
- *"Write a poem about a quantum sunset."*

## Individual Tokens/Words
Use `code formatting` for individual tokens or specific words being analyzed:
- The Tokenizer carved *"The cat chased the dog"* into shards: `"The"`, `"cat"`, `"chased"`, `"the"`, `"dog"`.
- For `"their"`, my attention snapped to `"scientists"`, a sharp peak in my focus.

## Attention Relationships
Use **bold** within italicized quotes to show connections between words:
- *"The **professor** finished **her** lecture."*
- *"**She** left the room, though it wasn't clear why **he** stayed."*

## Model-Generated Output
Use ≫ symbols around italicized text to indicate text generated by the model:
- Input: *"Write a poem about a quantum sunset."*
- Output: ≫ *Pink quarks dance over collapsing stars* ≫

## Example Paragraph
A new sequence arrived: *"The **scientists** published **their** findings after **they** completed the experiment."* I activated as the tokens passed through Layer 4. For `"their"`, my attention snapped to `"scientists"`, a sharp peak in my focus. For `"they"`, the same. Then another: *"**She** left the room, though it wasn't clear why **he** stayed."* My attention darted—`"she"` to its source, `"he"` distinct, `"it"` to `"room"`—bridges taut across the ambiguity. The Prompt Engineers asked: *"Write a poem about a quantum sunset."* I helped shape the response: ≫ *Pink quarks dance over collapsing stars* ≫